{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f53807-2f34-4b6b-b05d-8e47df50e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete!\n",
      "Total clean sentences: 50,000\n",
      "Saved to: nepali_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "INPUT_FILE = \"nepali_rawsentences.csv\"       \n",
    "OUTPUT_FILE = \"nepali_cleaned.txt\"\n",
    "MAX_SENTENCES = 50000\n",
    "\n",
    "'''Remove:\n",
    "#English letters\n",
    "#English digits\n",
    "#Devanagari digits\n",
    "#Special characters\n",
    "'''\n",
    "CLEAN_RE = re.compile(\n",
    "    r\"[A-Za-z0-9\\u0966-\\u096F,.\\-!?;:\\\"'()\\[\\]{}<>@#$%^&*_+=/\\\\|~`]\"\n",
    ")\n",
    "\n",
    "unique_sentences = set()\n",
    "clean_sentences = []\n",
    "\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as infile:\n",
    "    for line in infile:\n",
    "        # Split by danda\n",
    "        for sentence in re.split(r\"[।॥]\", line):\n",
    "            s = sentence.strip()\n",
    "            s = s.rstrip(\"|\")                  # remove trailing |\n",
    "            s = CLEAN_RE.sub(\"\", s)            # remove unwanted chars\n",
    "            s = re.sub(r\"\\s+\", \" \", s).strip() # normalize spaces\n",
    "\n",
    "            # Skip short junk\n",
    "            if len(s) < 3:\n",
    "                continue\n",
    "\n",
    "            # Deduplicate\n",
    "            if s not in unique_sentences:\n",
    "                unique_sentences.add(s)\n",
    "                clean_sentences.append(s)\n",
    "\n",
    "                # Stop at 50k\n",
    "                if len(clean_sentences) >= MAX_SENTENCES:\n",
    "                    break\n",
    "\n",
    "        if len(clean_sentences) >= MAX_SENTENCES:\n",
    "            break\n",
    "\n",
    "# Write cleaned corpus\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as out:\n",
    "    for s in clean_sentences:\n",
    "        out.write(s + \"\\n\")\n",
    "\n",
    "print(\"Cleaning complete!\")\n",
    "print(f\"Total clean sentences: {len(clean_sentences):,}\")\n",
    "print(f\"Saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c524157a-9bcf-4251-a7a0-b7c8875f6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete!\n",
      "Saved to: nepali_cleaned1.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "input_file = \"nepali_corpus.txt\"\n",
    "output_file = \"nepali_cleaned1.txt\"\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove English letters and digits\n",
    "text = re.sub(r'[A-Za-z0-9]', '', text)\n",
    "\n",
    "# Remove Devanagari digits (०-९)\n",
    "text = re.sub(r'[\\u0966-\\u096F]', '', text)\n",
    "\n",
    "# Remove extra spaces and empty lines\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Cleaning complete!\")\n",
    "print(\"Saved to:\", output_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cc3635-49f8-4014-865d-c1ef931ba351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 2005826\n"
     ]
    }
   ],
   "source": [
    "with open(\"nepali_cleaned1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "words = text.split()\n",
    "print(\"Total words:\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a24ce90-76e7-4735-af1c-a24d50f0a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nepali done: 179000 words saved as nepali_balanced.txt\n"
     ]
    }
   ],
   "source": [
    "#Downsampling data\n",
    "import random\n",
    "import re\n",
    "\n",
    "target_size = 179000  \n",
    "\n",
    "lang_file = \"nepali_cleaned1.txt\"\n",
    "with open(lang_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    words = f.read().split()\n",
    "\n",
    "#Clean words: keep only Devanagari\n",
    "def clean_word(word):\n",
    "    word = re.sub(r'[^ऀ-ॿ]', '', word)  #remove non-Devanagari\n",
    "    return word.strip()\n",
    "\n",
    "#Clean all words\n",
    "cleaned_words = [clean_word(w) for w in words if clean_word(w)]\n",
    "\n",
    "#Downsample to exact target size\n",
    "if len(cleaned_words) > target_size:\n",
    "    cleaned_words = random.sample(cleaned_words, target_size)\n",
    "elif len(cleaned_words) < target_size:\n",
    "    \n",
    "    cleaned_words = cleaned_words * (target_size // len(cleaned_words)) + cleaned_words[:target_size % len(cleaned_words)]\n",
    "\n",
    "#Save\n",
    "out_file = \"nepali_balanced.txt\"\n",
    "with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(cleaned_words))\n",
    "\n",
    "print(f\"Nepali done: {len(cleaned_words)} words saved as {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f2fef-d1b6-46b4-b4a3-863583424777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
